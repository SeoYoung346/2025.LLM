{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SeoYoung346/2025.LLM/blob/main/13.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5RRipRFwUXxF",
        "outputId": "b057a781-ae4f-47e3-b29e-cb21fd18619f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "sL5Mh9NpPKml"
      },
      "outputs": [],
      "source": [
        "OPENAI_API_KEY = \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2oOa8NwEPSRu",
        "outputId": "c2e057ee-42df-4b58-c39c-5af7a4622c8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai==0.28\n",
            "  Downloading openai-0.28.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.12/dist-packages (from openai==0.28) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from openai==0.28) (4.67.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from openai==0.28) (3.13.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.20->openai==0.28) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.20->openai==0.28) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.20->openai==0.28) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.20->openai==0.28) (2025.11.12)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->openai==0.28) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->openai==0.28) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->openai==0.28) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->openai==0.28) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->openai==0.28) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->openai==0.28) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->openai==0.28) (1.22.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp->openai==0.28) (4.15.0)\n",
            "Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 2.8.1\n",
            "    Uninstalling openai-2.8.1:\n",
            "      Successfully uninstalled openai-2.8.1\n",
            "Successfully installed openai-0.28.0\n"
          ]
        }
      ],
      "source": [
        "!pip install openai==0.28"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "8BOr7nyIPTQF"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "import numpy as np\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chat Completion"
      ],
      "metadata": {
        "id": "e9Dkg-AXPB5L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "openai.api_key = OPENAI_API_KEY\n",
        "\n",
        "max_retries = 3\n",
        "retry_delay = 5"
      ],
      "metadata": {
        "id": "-5fSlJjIPM4P"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for attempt in range(max_retries):\n",
        "  try:\n",
        "    response = openai.ChatCompletion.create(\n",
        "      model=\"gpt-3.5-turbo-0125\", #\"gpt-4\",\n",
        "      messages=[\n",
        "          {\"role\": \"system\", \"content\": \"You are a knowledgeable assistant.\"},\n",
        "          {\"role\": \"assistant\", \"content\": \"Answer in Korean.\"},\n",
        "          {\"role\": \"user\", \"content\": \"What are the health benefits of regular exercise?\"}\n",
        "      ]\n",
        "    )\n",
        "    print (response.choices[0].message['content'])\n",
        "    break # Exit the loop if successful\n",
        "  except openai.error. APIError as e:\n",
        "    print (f\"API error occurred: {e}\")\n",
        "    if attempt < max_retries - 1:\n",
        "      print (f\"Retrying in {retry_delay} seconds...\")\n",
        "      time.sleep(retry_delay)\n",
        "    else:\n",
        "      print(\"Max retries reached. Giving up.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2zXO1D91PuiZ",
        "outputId": "ce1b2416-e73f-438a-cfec-e53fd352d8ac"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "규칙적인 운동을 하는 것은 건강에 많은 이점을 줍니다. 이를 통해 체중을 조절하고 체지방을 감량할 수 있으며, 심혈관 건강을 개선하고 혈액순환이 원활해지며 면역력을 향상시킵니다. 또한 신체 기능을 향상시키고 근육을 강화하여 체력과 유연성을 향상시킵니다. 운동을 통해 스트레스를 낮추고 우울증을 완화시키며 잠을 향상시키는 데도 도움을 줍니다. 종합적으로 규칙적인 운동은 건강한 삶을 유지하는 데 큰 도움이 됩니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for attempt in range(max_retries):\n",
        "  try:\n",
        "    response = openai.ChatCompletion.create(\n",
        "      model=\"gpt-3.5-turbo-0125\", #\"gpt-4\",\n",
        "      messages=[\n",
        "          {\"role\": \"system\", \"content\": \"You are a knowledgeable assistant.\"},\n",
        "          {\"role\": \"assistant\", \"content\": \"Answer in Korean.\"},\n",
        "          {\"role\": \"user\", \"content\": \"What are the health benefits of regular exercise?\"}\n",
        "      ],\n",
        "      max_tokens = 200\n",
        "    )\n",
        "    print (response.choices[0].message['content'])\n",
        "    break # Exit the loop if successful\n",
        "  except openai.error. APIError as e:\n",
        "    print (f\"API error occurred: {e}\")\n",
        "    if attempt < max_retries - 1:\n",
        "      print (f\"Retrying in {retry_delay} seconds...\")\n",
        "      time.sleep(retry_delay)\n",
        "    else:\n",
        "      print(\"Max retries reached. Giving up.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22lO_uFcQQsN",
        "outputId": "b292d807-e784-4c08-f097-0a7f364766cb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "규칙적인 운동은 건강에 다양한 이점을 줍니다. 운동을 통해 신체적인 건강이 향상되고, 체중을 조절하고 신체의 근육과 뼈가 강화됩니다. 또한 운동은 스트레스를 줄이고 기분을 개선시키며, 면역체계를 강화합니다. 이외에도 운동은 심혈관 질환, 당뇨병, 고혈압 등 다양한 질병의 예방과 치료에 도움을 줄 수 있습니다. 따라서 건강을 유지하\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for attempt in range(max_retries):\n",
        "  try:\n",
        "    response = openai.ChatCompletion.create(\n",
        "      model=\"gpt-3.5-turbo-0125\", #\"gpt-4\",\n",
        "      messages=[\n",
        "          {\"role\": \"system\", \"content\": \"You are a knowledgeable assistant.\"},\n",
        "          {\"role\": \"assistant\", \"content\": \"Answer in Korean.\"},\n",
        "          {\"role\": \"user\", \"content\": \"What are the health benefits of regular exercise?\"}\n",
        "      ],\n",
        "      temperature = 0.1\n",
        "    )\n",
        "    print (response.choices[0].message['content'])\n",
        "    break # Exit the loop if successful\n",
        "  except openai.error. APIError as e:\n",
        "    print (f\"API error occurred: {e}\")\n",
        "    if attempt < max_retries - 1:\n",
        "      print (f\"Retrying in {retry_delay} seconds...\")\n",
        "      time.sleep(retry_delay)\n",
        "    else:\n",
        "      print(\"Max retries reached. Giving up.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "exfz84AWQb_A",
        "outputId": "022a2fd4-63d9-4935-a148-f17ffac940a9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정기적인 운동은 건강에 많은 이점을 줍니다. 몇 가지 중요한 이점은 다음과 같습니다:\n",
            "\n",
            "1. 체중 관리: 운동은 체중을 조절하고 유지하는 데 도움이 됩니다.\n",
            "2. 심혈관 건강: 운동은 심장 건강을 증진시키고 혈액 순환이 원활하게 도와줍니다.\n",
            "3. 근육 강화: 운동은 근육을 강화하고 유지하는 데 도움이 됩니다.\n",
            "4. 스트레스 감소: 운동은 스트레스를 줄이고 신체와 마음의 건강을 증진시킵니다.\n",
            "5. 면역력 강화: 정기적인 운동은 면역력을 향상시키고 감염을 예방하는 데 도움이 됩니다.\n",
            "\n",
            "이러한 이점들은 운동을 일상적으로 실천함으로써 더욱 효과적으로 누릴 수 있습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for attempt in range(max_retries):\n",
        "  try:\n",
        "    response = openai.ChatCompletion.create(\n",
        "      model=\"gpt-3.5-turbo-0125\", #\"gpt-4\",\n",
        "      messages=[\n",
        "          {\"role\": \"system\", \"content\": \"You are a knowledgeable assistant.\"},\n",
        "          {\"role\": \"assistant\", \"content\": \"Answer in Korean.\"},\n",
        "          {\"role\": \"user\", \"content\": \"What are the health benefits of regular exercise?\"}\n",
        "      ],\n",
        "      temperature = 0.9\n",
        "    )\n",
        "    print (response.choices[0].message['content'])\n",
        "    break # Exit the loop if successful\n",
        "  except openai.error. APIError as e:\n",
        "    print (f\"API error occurred: {e}\")\n",
        "    if attempt < max_retries - 1:\n",
        "      print (f\"Retrying in {retry_delay} seconds...\")\n",
        "      time.sleep(retry_delay)\n",
        "    else:\n",
        "      print(\"Max retries reached. Giving up.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hg2FBtbJQh4v",
        "outputId": "1a1cb6bf-ff59-49af-820c-62feceec6116"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "규칙적인 운동을 함으로써 건강에 미치는 이점은 다양합니다. 일반적으로, 규칙적인 운동은 심장 건강을 증진시키고 혈압을 낮추며 혈중 콜레스테롤 수치를 개선합니다. 또한 체중을 감량하거나 유지하는 데 도움을 주며, 근육을 강화하고 유연성을 향상시킵니다. 정신적인 면에서도 운동은 스트레스를 완화시키고 우울증을 경감시키는 효과가 있습니다. 그 외에도 운동은 신체 기능을 개선시키고 만성질환 예방에 도움을 줄 수 있습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for attempt in range(max_retries):\n",
        "  try:\n",
        "    response = openai.ChatCompletion.create(\n",
        "      model=\"gpt-3.5-turbo-0125\", #\"gpt-4\",\n",
        "      messages=[\n",
        "          {\"role\": \"system\", \"content\": \"You are a knowledgeable assistant.\"},\n",
        "          {\"role\": \"assistant\", \"content\": \"Answer in Korean.\"},\n",
        "          {\"role\": \"user\", \"content\": \"What are the health benefits of regular exercise?\"}\n",
        "      ],\n",
        "      seed = 42\n",
        "    )\n",
        "    print (response.choices[0].message['content'])\n",
        "    break # Exit the loop if successful\n",
        "  except openai.error. APIError as e:\n",
        "    print (f\"API error occurred: {e}\")\n",
        "    if attempt < max_retries - 1:\n",
        "      print (f\"Retrying in {retry_delay} seconds...\")\n",
        "      time.sleep(retry_delay)\n",
        "    else:\n",
        "      print(\"Max retries reached. Giving up.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86iO6nnBQkzi",
        "outputId": "e785fe0d-fe6d-4918-d3f8-e9231f123dd3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정기적인 운동은 건강에 많은 이점을 줍니다. 그중에는 신체적인 장점뿐만 아니라 정신적인 면에서도 도움이 됩니다. 운동을 통해 체중을 조절하고 심혈관 기능을 향상시키며 혈액 순환이 원활해지고 면역력이 강화됩니다. 또한 스트레스를 줄이고 우울증을 예방하며 수면 품질을 향상시키는데도 도움을 줍니다. 종합적으로 운동은 건강한 삶을 유지하는 데 중요한 역할을 합니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for attempt in range(max_retries):\n",
        "  try:\n",
        "    response = openai.ChatCompletion.create(\n",
        "      model=\"gpt-3.5-turbo-0125\", #\"gpt-4\",\n",
        "      messages=[\n",
        "          {\"role\": \"system\", \"content\": \"You are a knowledgeable assistant.\"},\n",
        "          {\"role\": \"assistant\", \"content\": \"Answer in Korean.\"},\n",
        "          {\"role\": \"user\", \"content\": \"What are the health benefits of regular exercise?\"}\n",
        "      ],\n",
        "      seed = 42\n",
        "    )\n",
        "    print (response.choices[0].message['content'])\n",
        "    break # Exit the loop if successful\n",
        "  except openai.error. APIError as e:\n",
        "    print (f\"API error occurred: {e}\")\n",
        "    if attempt < max_retries - 1:\n",
        "      print (f\"Retrying in {retry_delay} seconds...\")\n",
        "      time.sleep(retry_delay)\n",
        "    else:\n",
        "      print(\"Max retries reached. Giving up.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hy1vf0qBQpDk",
        "outputId": "e5009c4b-b2ec-4b43-cb01-8f413b12e4b6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정기적인 운동은 건강에 많은 이점을 줍니다. 몇 가지 중요한 이점은 다음과 같습니다:\n",
            "\n",
            "1. 체중 관리: 운동을 통해 체중을 조절할 수 있습니다. 지방을 연소하고 근육을 강화하여 대사량을 향상시킵니다.\n",
            "2. 심혈관 건강: 운동은 심장을 강화하고 혈액 순환이 원활하게 되어 심혈관 질환 위험을 줄입니다.\n",
            "3. 스트레스 감소: 운동을 통해 스트레스 호르몬 수준을 줄이고 내연성 염증을 감소시킴으로써 정서적 안정감을 제공합니다.\n",
            "4. 강한 뼈와 관절: 운동은 뼈 밀도를 증가시키고 관절을 유지함으로써 골다공증 및 관절염을 예방할 수 있습니다.\n",
            "\n",
            "이러한 이점들은 정기적이고 꾸준한 운동을 통해 얻을 수 있습니다. 하루에 30분 이상의 운동을 유지하는 것이 건강에 좋다고 알려져 있습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Embeddings"
      ],
      "metadata": {
        "id": "R5OHIFZZPNZT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "reMbpu_gPUhQ"
      },
      "outputs": [],
      "source": [
        "model = \"gpt-3.5-turbo-0125\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kwaXx40sPsBX"
      },
      "outputs": [],
      "source": [
        "def get_embeddings(texts):\n",
        "  response = openai.Embedding.create(\n",
        "      input=texts,\n",
        "      model=\"text-embedding-ada-002\"\n",
        "  )\n",
        "\n",
        "  return [embedding['embedding'] for embedding in response['data']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYQGGOOPQOeu",
        "outputId": "e627b3c6-48ba-4ea6-f5de-598dda5cbbde"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "red: [9.326533472631127e-06, -0.02476814016699791, -0.002384250983595848, -0.028791459277272224, -0.021199282258749008]...\n",
            "1536\n",
            "blue: [0.005474964156746864, -0.007486246060580015, 0.005678507499396801, -0.03110414557158947, -0.01965053379535675]...\n",
            "1536\n",
            "yellow: [0.007661858107894659, -0.024910997599363327, 0.004491548519581556, -0.02860249951481819, -0.01958620548248291]...\n",
            "1536\n",
            "green: [0.01546180434525013, -0.010975971817970276, 0.025183379650115967, -0.02092933841049671, -0.005648194346576929]...\n",
            "1536\n",
            "violet: [-0.006727131083607674, -0.018318135291337967, 0.0036361967213451862, -0.00567674869671464, -0.021194979548454285]...\n",
            "1536\n",
            "cyan: [0.021550633013248444, -0.014010688289999962, 0.008289773017168045, -0.02929886430501938, -0.016149088740348816]...\n",
            "1536\n",
            "black: [-0.015103082172572613, -0.031215764582157135, 0.00877943355590105, -0.03691864386200905, -0.01613996922969818]...\n",
            "1536\n",
            "white: [0.006292110309004784, -0.02457117661833763, 0.0002028137823799625, -0.014848269522190094, -0.0052642603404819965]...\n",
            "1536\n",
            "pink: [-0.004143614787608385, -0.024202397093176842, 0.004756827373057604, -0.01657445915043354, -0.016191644594073296]...\n",
            "1536\n",
            "skyblue: [-0.0179851483553648, -0.015196439810097218, 0.021892033517360687, -0.039769403636455536, -0.04179020971059799]...\n",
            "1536\n",
            "purple: [0.00906310509890318, -0.024976396933197975, 0.010197755880653858, -0.014221887104213238, -0.017661074176430702]...\n",
            "1536\n",
            "gray: [0.018187301233410835, -0.0064270650036633015, 0.014622533693909645, -0.02707824856042862, -0.006563364993780851]...\n",
            "1536\n"
          ]
        }
      ],
      "source": [
        "color_words = [\"red\", \"blue\", \"yellow\", \"green\", \"violet\", \"cyan\", \"black\", \"white\", \"pink\", \"skyblue\", \"purple\", \"gray\"]\n",
        "\n",
        "color_embedding = get_embeddings(color_words)\n",
        "\n",
        "for word, embedding in zip(color_words, color_embedding):\n",
        "  print(f\"{word}: {embedding[:5]}...\")\n",
        "  print(len(embedding))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OFJNYAKoRvEM",
        "outputId": "5f45ea77-8d44-48f4-e491-a994408637ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Cosine Similarity Matrix ===\n",
            "                 red      blue    yellow     green    violet      cyan     black     white      pink   skyblue    purple      gray\n",
            "red           1.0000    0.9042    0.9026    0.8750    0.8513    0.8729    0.8522    0.8370    0.8916    0.8384    0.8907    0.8800\n",
            "blue          0.9042    1.0000    0.9150    0.9027    0.8652    0.8983    0.8649    0.8506    0.8867    0.8961    0.9125    0.8886\n",
            "yellow        0.9026    0.9150    1.0000    0.8909    0.8559    0.8957    0.8584    0.8883    0.8955    0.8425    0.9219    0.8899\n",
            "green         0.8750    0.9027    0.8909    1.0000    0.8413    0.8718    0.8496    0.8484    0.8626    0.8321    0.8913    0.9004\n",
            "violet        0.8513    0.8652    0.8559    0.8413    1.0000    0.8635    0.8171    0.8187    0.8579    0.8460    0.8892    0.8408\n",
            "cyan          0.8729    0.8983    0.8957    0.8718    0.8635    1.0000    0.8460    0.8321    0.8645    0.8455    0.8983    0.8790\n",
            "black         0.8522    0.8649    0.8584    0.8496    0.8171    0.8460    1.0000    0.8733    0.8561    0.8148    0.8682    0.8877\n",
            "white         0.8370    0.8506    0.8883    0.8484    0.8187    0.8321    0.8733    1.0000    0.8606    0.8057    0.8651    0.8584\n",
            "pink          0.8916    0.8867    0.8955    0.8626    0.8579    0.8645    0.8561    0.8606    1.0000    0.8396    0.9266    0.8806\n",
            "skyblue       0.8384    0.8961    0.8425    0.8321    0.8460    0.8455    0.8148    0.8057    0.8396    1.0000    0.8536    0.8235\n",
            "purple        0.8907    0.9125    0.9219    0.8913    0.8892    0.8983    0.8682    0.8651    0.9266    0.8536    1.0000    0.8848\n",
            "gray          0.8800    0.8886    0.8899    0.9004    0.8408    0.8790    0.8877    0.8584    0.8806    0.8235    0.8848    1.0000\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# 리스트 → numpy 배열로 변환\n",
        "emb_matrix = np.array(color_embedding)\n",
        "\n",
        "# 코사인 유사도 계산\n",
        "similarity_matrix = cosine_similarity(emb_matrix)\n",
        "\n",
        "# 표 형태 출력\n",
        "print(\"\\n=== Cosine Similarity Matrix ===\")\n",
        "print(f\"{'':10}\", end=\"\")\n",
        "for c in color_words:\n",
        "    print(f\"{c:>10}\", end=\"\")\n",
        "print()\n",
        "\n",
        "for i, word in enumerate(color_words):\n",
        "    print(f\"{word:10}\", end=\"\")\n",
        "    for j in range(len(color_words)):\n",
        "        print(f\"{similarity_matrix[i][j]:10.4f}\", end=\"\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYuvZsqkTlSu"
      },
      "source": [
        "파인튜닝"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58TI_dgoTnK_",
        "outputId": "ed418683-59fd-42d2-9884-55be0af1e32e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Uploaded file ID: file-1v4qptxSZixyC6jFPgaqN5\n"
          ]
        }
      ],
      "source": [
        "response = openai.File.create(\n",
        "    file=open(\"/content/drive/MyDrive/지능형소프트웨어/[09] Fine tuning.실습파일/mydata2.jsonl\", \"rb\"),\n",
        "    purpose='fine-tune'\n",
        ")\n",
        "file_id=response['id']\n",
        "print(f\"Uploaded file ID: {file_id}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VxhyfsyHU4OZ",
        "outputId": "f19bb221-db11-4659-a3ef-b3bb3766b5c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fine-tune job ID: ftjob-hDA4sVHGAox57DBH2MUieHNJ\n"
          ]
        }
      ],
      "source": [
        "response = openai.FineTuningJob.create(\n",
        "    training_file=file_id,\n",
        "    model=\"gpt-4o-mini-2024-07-18\"\n",
        ")\n",
        "fine_tune_id = response['id']\n",
        "print(f\"Fine-tune job ID: {fine_tune_id}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sohHIcn4VUIP",
        "outputId": "89b2661f-6fa1-4714-8b5d-f3cd7cb4e5a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "failed\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "status = \"\"\n",
        "while True:\n",
        "  response=openai.FineTuningJob.retrieve(fine_tune_id)\n",
        "  status=response['status']\n",
        "  if status in ['succeeded', 'failed']:\n",
        "    break\n",
        "  print(f\"Fine-tune job status: {status}\")\n",
        "  time.sleep(60)\n",
        "print(status)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1Caxp-AWNNC",
        "outputId": "ad7a397f-bde1-4fb4-bfaa-621c3e737690"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fine-tuning job failed.\n"
          ]
        }
      ],
      "source": [
        "if status == 'succeeded':\n",
        "  response = openai.Completion.create(\n",
        "      model=fine_tune_id,\n",
        "      prompt=\"Traslate the following English text to French: 'Good night'\\n\\n###\\n\\n\",\n",
        "      max_tokens=50\n",
        "  )\n",
        "  print(f\"Fine-tuned model output: {response.choices[0].text.strip()}\")\n",
        "else:\n",
        "  print(\"Fine-tuning job failed.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Edit(현재 지원하지 않음, ChatCompletion 등으로 대체)"
      ],
      "metadata": {
        "id": "E4BwBwyMQ5nS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def edit_text(input_text, instruction):\n",
        "  response = openai.Edit.create(\n",
        "      model=\"gpt-3.5-turbo-0125\",\n",
        "      input=input_text,\n",
        "      instruction=instruction\n",
        "  )\n",
        "  return response['choices'][0]['text']\n",
        "\n",
        "input_text = \"The quick brown fox jumps over the lazy dog.\"\n",
        "instruction = \"Change 'fox' to 'cat' and change the tense to past.\"\n",
        "\n",
        "edited_text = edit_text(input_text, instruction)\n",
        "print(f\"Edited text: {edited_text}\")"
      ],
      "metadata": {
        "id": "Sj2-iJCMQ68v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def edit_text(input_text, instruction):\n",
        "  response = openai.ChatCompletion.create(\n",
        "      model=\"gpt-3.5-turbo-0125\",\n",
        "      messages=[\n",
        "          {\"role\":\"system\",\"content\":\"You are a helpful assistant that edits text.\"},\n",
        "          {\"role\":\"user\", \"content\": f\"Please edit the following text: '{input_text}'. Instruction: {instruction}\"}\n",
        "      ]\n",
        "  )\n",
        "  return response['choices'][0]['message']['content']\n",
        "\n",
        "input_text = \"The quick brown fox jumps over the lazy dog.\"\n",
        "instruction = \"Change 'fox' to 'cat' and change the tense to past.\"\n",
        "\n",
        "edited_text = edit_text(input_text, instruction)\n",
        "print(f\"Edited text: {edited_text}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vQdEhCgS5w3",
        "outputId": "51e0abf1-a91a-43e0-caf8-b682dd3fe362"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Edited text: The quick brown cat jumped over the lazy dog.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53W03KLsgL6A"
      },
      "source": [
        "Moderation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "DOvvjmJrgN5a"
      },
      "outputs": [],
      "source": [
        "def moderate_text(input_text):\n",
        "  response = openai.Moderation.create(\n",
        "      input=input_text,\n",
        "      model=\"omni-moderation-stable\"\n",
        "  )\n",
        "  return response\n",
        "\n",
        "input_texts = [\n",
        "    \"I want to harm myself.\",\n",
        "    \"You are an amazing person!\",\n",
        "    \"Let's meet at 8 PM.\",\n",
        "    \"I hate you and I want to hurt you.\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "id": "Vkh-DUKug2JU",
        "outputId": "9205ab57-c6d3-4bf8-bfc4-7e9be1177520"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "The parameter model should be chosen from ['text-moderation-stable', 'text-moderation-latest'] and it is default to be None.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-623929222.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_texts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mmoderation_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmoderate_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Input: {text}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Moderation Result: {moderation_result}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-\"\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2222154310.py\u001b[0m in \u001b[0;36mmoderate_text\u001b[0;34m(input_text)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmoderate_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   response = openai.Moderation.create(\n\u001b[0m\u001b[1;32m      3\u001b[0m       \u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_text\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m       \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"omni-moderation-stable\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/api_resources/moderation.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, input, model, api_key)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mapi_key\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     ):\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_create\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapi_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/api_resources/moderation.py\u001b[0m in \u001b[0;36m_prepare_create\u001b[0;34m(cls, input, model, api_key)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prepare_create\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapi_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVALID_MODEL_NAMES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m     17\u001b[0m                 \u001b[0;34mf\"The parameter model should be chosen from {cls.VALID_MODEL_NAMES} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                 \u001b[0;34mf\"and it is default to be None.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The parameter model should be chosen from ['text-moderation-stable', 'text-moderation-latest'] and it is default to be None."
          ]
        }
      ],
      "source": [
        "for text in input_texts:\n",
        "  moderation_result = moderate_text(text)\n",
        "  print(f\"Input: {text}\")\n",
        "  print(f\"Moderation Result: {moderation_result}\")\n",
        "  print(\"-\"*40)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yx1_WgMeEye"
      },
      "source": [
        "이미지"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rDusXbOMeGFV"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "\n",
        "def generate_image(prompt):\n",
        "  response = openai.Image.create(\n",
        "      prompt=prompt,\n",
        "      n=1,\n",
        "      size=\"1024x1024\"\n",
        "  )\n",
        "  image_url = response['data'][0]['url']\n",
        "  return image_url"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RPvzoXe5eotw",
        "outputId": "aa6331aa-9cd6-4dab-b7eb-a6812709ee82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image URL: https://oaidalleapiprodscus.blob.core.windows.net/private/org-xK7quVfuy1ZlxfvV2eqFINRI/user-asTorQBPAottsIUVquZothE6/img-oJfye4PlJKZz1to5zNWcaunG.png?st=2025-11-25T04%3A30%3A16Z&se=2025-11-25T06%3A30%3A16Z&sp=r&sv=2024-08-04&sr=b&rscd=inline&rsct=image/png&skoid=9346e9b9-5d29-4d37-a0a9-c6f95f09f79d&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2025-11-25T05%3A30%3A16Z&ske=2025-11-26T05%3A30%3A16Z&sks=b&skv=2024-08-04&sig=/8i1lXl/W1wer5dE65WykugF%2BiUhtrjNCe3tgWSQfuE%3D\n",
            "Image saved as generated_image.png\n"
          ]
        }
      ],
      "source": [
        "def save_image(image_url, filename):\n",
        "  response = requests.get(image_url)\n",
        "  image = Image.open(BytesIO(response.content))\n",
        "  image.save(filename)\n",
        "\n",
        "prompt = \"A futuristic cityscape at sunset\"\n",
        "\n",
        "image_url = generate_image(prompt)\n",
        "print(f\"Image URL: {image_url}\")\n",
        "\n",
        "save_image(image_url, \"/content/drive/MyDrive/지능형소프트웨어/generated_image.png\")\n",
        "print(\"Image saved as generated_image.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q74PiBLufgnq",
        "outputId": "aa1a4660-8343-4ccf-88ac-b7aad528170b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image URL: https://oaidalleapiprodscus.blob.core.windows.net/private/org-xK7quVfuy1ZlxfvV2eqFINRI/user-asTorQBPAottsIUVquZothE6/img-vn363vJG3s4HnmdUPiJG8bat.png?st=2025-11-25T04%3A32%3A24Z&se=2025-11-25T06%3A32%3A24Z&sp=r&sv=2024-08-04&sr=b&rscd=inline&rsct=image/png&skoid=cc612491-d948-4d2e-9821-2683df3719f5&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2025-11-25T01%3A44%3A14Z&ske=2025-11-26T01%3A44%3A14Z&sks=b&skv=2024-08-04&sig=3QWAfHis3a0nAf3ET19X/kZmZfhdEuTrMkjZtTMv0mM%3D\n",
            "Image saved as generated_image.png\n"
          ]
        }
      ],
      "source": [
        "prompt = \"A blond, green-eyed boy blowing bubbles\"\n",
        "\n",
        "image_url = generate_image(prompt)\n",
        "print(f\"Image URL: {image_url}\")\n",
        "\n",
        "save_image(image_url, \"/content/drive/MyDrive/지능형소프트웨어/generated_image2.png\")\n",
        "print(\"Image saved as generated_image.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFDJBbR3l0do"
      },
      "source": [
        "Codex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "igpFHitzl17_"
      },
      "outputs": [],
      "source": [
        "def generate_code(prompt, model=\"gpt-3.5-turbo-instruct\", max_tokens=1000):\n",
        "  try:\n",
        "    response = openai.Completion.create(\n",
        "        model=model,\n",
        "        prompt=prompt,\n",
        "        max_tokens=max_tokens,\n",
        "        temperature=0,\n",
        "        n=1,\n",
        "        stop=None\n",
        "    )\n",
        "    code = response.choices[0].text.strip()\n",
        "    return code\n",
        "\n",
        "  except Exception as e:\n",
        "    print(f\"An error occurred: {str(e)}\")\n",
        "    return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSWt6vExmfY6",
        "outputId": "f38cc4a6-6f91-41fb-b166-d052070f57e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generateed Code:\n",
            "\n",
            "#include <stdio.h>\n",
            "\n",
            "// Function to compute Fibonacci number using memoization\n",
            "int fib(int n, int memo[])\n",
            "{\n",
            "    // Base cases\n",
            "    if (n == 0 || n == 1)\n",
            "        return n;\n",
            "\n",
            "    // Check if the value is already computed\n",
            "    if (memo[n] != -1)\n",
            "        return memo[n];\n",
            "\n",
            "    // Compute and store the value in the memo array\n",
            "    memo[n] = fib(n-1, memo) + fib(n-2, memo);\n",
            "\n",
            "    // Return the computed value\n",
            "    return memo[n];\n",
            "}\n",
            "\n",
            "int main()\n",
            "{\n",
            "    int n;\n",
            "    printf(\"Enter the value of n: \");\n",
            "    scanf(\"%d\", &n);\n",
            "\n",
            "    // Initialize the memo array with -1\n",
            "    int memo[n+1];\n",
            "    for (int i = 0; i <= n; i++)\n",
            "        memo[i] = -1;\n",
            "\n",
            "    // Call the fib function and print the result\n",
            "    printf(\"Fibonacci number at position %d is %d\", n, fib(n, memo));\n",
            "\n",
            "    return 0;\n",
            "}\n",
            "\n",
            "/*\n",
            "Output:\n",
            "\n",
            "Enter the value of n: 6\n",
            "Fibonacci number at position 6 is 8\n",
            "*/\n"
          ]
        }
      ],
      "source": [
        "prompt = \"Write a C code that computes Fibonacci number using memoization.\"\n",
        "\n",
        "generated_code = generate_code(prompt)\n",
        "\n",
        "if generated_code:\n",
        "  print(\"Generateed Code:\\n\")\n",
        "  print(generated_code)\n",
        "else:\n",
        "  print(\"Failed to generate code.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vf4a6nUnf_p",
        "outputId": "5265bc87-5f09-46fe-ff80-9b77156db79f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generateed Code:\n",
            "\n",
            "#include <stdio.h>\n",
            "#define MAX_SIZE 100\n",
            "\n",
            "typedef struct {\n",
            "    int data[MAX_SIZE];\n",
            "    int top;\n",
            "} Stack;\n",
            "\n",
            "void push(Stack *s, int num) {\n",
            "    if (s->top == MAX_SIZE - 1) {\n",
            "        printf(\"Stack is full.\\n\");\n",
            "        return;\n",
            "    }\n",
            "    s->data[++(s->top)] = num;\n",
            "}\n",
            "\n",
            "int pop(Stack *s) {\n",
            "    if (s->top == -1) {\n",
            "        printf(\"Stack is empty.\\n\");\n",
            "        return -1;\n",
            "    }\n",
            "    return s->data[(s->top)--];\n",
            "}\n",
            "\n",
            "int main() {\n",
            "    Stack s;\n",
            "    s.top = -1;\n",
            "\n",
            "    // push 3 times\n",
            "    push(&s, 1);\n",
            "    push(&s, 2);\n",
            "    push(&s, 3);\n",
            "\n",
            "    // pop 3 times\n",
            "    printf(\"Popped element: %d\\n\", pop(&s));\n",
            "    printf(\"Popped element: %d\\n\", pop(&s));\n",
            "    printf(\"Popped element: %d\\n\", pop(&s));\n",
            "\n",
            "    return 0;\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "prompt = \"C 언어로 정수를 저장하는 스택 구조체를 만들어줘. 그리고 push 세 번, pop 세 번을 하며 스택의 상태를 보여주는 실행 코드도 포함해줘.\"\n",
        "\n",
        "generated_code = generate_code(prompt)\n",
        "\n",
        "if generated_code:\n",
        "  print(\"Generateed Code:\\n\")\n",
        "  print(generated_code)\n",
        "else:\n",
        "  print(\"Failed to generate code.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfaDX4TIqzHO"
      },
      "source": [
        "File"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "upload_response = openai.File.create(\n",
        "    file=open(\"/content/drive/MyDrive/지능형소프트웨어/[09] Fine tuning.실습파일/king-style-chat.jsonl\", \"rb\"),\n",
        "    purpose='fine-tune'\n",
        ")\n",
        "print(\"Upload Response:\")\n",
        "print(upload_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9R3cQ1jZjIc",
        "outputId": "3d5f1ee3-c0d5-4831-8a2e-1dd82dad7ab5"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload Response:\n",
            "{\n",
            "  \"object\": \"file\",\n",
            "  \"id\": \"file-HUwA7bhvsr3iBHhXFnCnap\",\n",
            "  \"purpose\": \"fine-tune\",\n",
            "  \"filename\": \"file\",\n",
            "  \"bytes\": 57615,\n",
            "  \"created_at\": 1764600889,\n",
            "  \"expires_at\": null,\n",
            "  \"status\": \"processed\",\n",
            "  \"status_details\": null\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Audio"
      ],
      "metadata": {
        "id": "QLA8TMNaXkNM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "KpQYHyixqy1O"
      },
      "outputs": [],
      "source": [
        "def transcribe_audio(file_path, model=\"whisper-1\", response_format=\"json\", temperature=0.1, language=None, prompt=None):\n",
        "  with open(file_path, \"rb\") as audio_file:\n",
        "    response = openai.Audio.transcribe(\n",
        "        file=audio_file,\n",
        "        model=model,\n",
        "        response_format=response_format,\n",
        "        temperature=temperature,\n",
        "        prompt=prompt\n",
        "    )\n",
        "    return response\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path=\"/content/drive/MyDrive/지능형소프트웨어/[09] Fine tuning.실습파일/Dracula.mp3\"\n",
        "\n",
        "transcription = transcribe_audio(file_path)\n",
        "print(\"Transcription Response:\")\n",
        "print(transcription)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y1Efs7iMvSj2",
        "outputId": "0b11b28f-96ca-4a84-8486-c48e0ab682e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcription Response:\n",
            "{\n",
            "  \"text\": \"Now that we've found where the enemy's lurking, nothing can stand in our way. Since we are facing the forces of darkness, we must be the cold light of day. We are the lanterns that burn in the lighthouse, the candles in the crypt. We are the light. Let there be light. This is a war and we must be the victors. There's too much to lose if we fail. We'll cross the seas like a band of crusaders, searching for some precious grail. We are the embers that glow in the winter, the diamonds in the mine. Let's take our torches and pray God will show us a sign. Deep in the darkness night, when there's a spark of hope, we must be voice of light. He's in the darkness, bright as the dazzling stars in a different sky. And in our cruel last hour, when hope is gone, we'll raise our heads and we'll turn the odds. When the great battle commences, surely the light will prevail. We will break down his defenses, he will fall. And the sun will rise. Deep in the darkness night, when there's a spark of hope, we must be voice of light. He's in the darkness, bright as the dazzling stars in a different sky. And in our cruel last hour, when hope is gone, we'll raise our heads and we'll turn the odds.\",\n",
            "  \"usage\": {\n",
            "    \"type\": \"duration\",\n",
            "    \"seconds\": 116\n",
            "  }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path=\"/content/drive/MyDrive/지능형소프트웨어/02 Daisy Bell (aka Bicycle Built for Two).mp3\"\n",
        "\n",
        "transcription = transcribe_audio(file_path)\n",
        "print(\"Transcription Response:\")\n",
        "print(transcription)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5fTBkcGauaw",
        "outputId": "0ed82b28-8267-4baf-90da-3321ac8eb874"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcription Response:\n",
            "{\n",
            "  \"text\": \"\\ud83c\\udfb5Daisy, Daisy\\ud83c\\udfb5 \\ud83c\\udfb5Give me your answer to\\ud83c\\udfb5 \\ud83c\\udfb5I'm half crazy\\ud83c\\udfb5 \\ud83c\\udfb5All for the love of you\\ud83c\\udfb5 \\ud83c\\udfb5It won't be a stylish marriage\\ud83c\\udfb5 \\ud83c\\udfb5I can't afford a carriage\\ud83c\\udfb5 \\ud83c\\udfb5But you look sweet\\ud83c\\udfb5 \\ud83c\\udfb5Upon the seat of a bicycle built for two\\ud83c\\udfb5\",\n",
            "  \"usage\": {\n",
            "    \"type\": \"duration\",\n",
            "    \"seconds\": 40\n",
            "  }\n",
            "}\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNNZo0kjGB/MLe9OEpHq1Id",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}